{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FilterNet\n",
    "A neural network for filtering out gaussian noise from an image introduced by aggressive accelerations on the vehicle carrying the camera. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jrached/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import torch \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from scipy.spatial.transform import Rotation as R \n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform \n",
    "from PIL import Image    \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from torchvision import transforms, utils \n",
    "from typing import List, Dict, Tuple \n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset class \n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, path_to_data, augmented=False, num_vids=7):\n",
    "        \"\"\"\n",
    "        Go through each video folder and build a map from \n",
    "        index i in range [0, N], where N is the total number\n",
    "        of frames in all the videos, to a tuple (j, k), where \n",
    "        j is the video number and k the frame index in that \n",
    "        video. For reference, the videos are stored in the \n",
    "        dataset as:  \n",
    "\n",
    "        data: \n",
    "        - test1: \n",
    "          - inputs:\n",
    "            - bd_poses.csv\n",
    "            - bd_twists.csv\n",
    "            - frame0000.png\n",
    "            - frame0001.png\n",
    "            - ... \n",
    "          - targets: \n",
    "            - frame0000.png\n",
    "            - frame0001.png\n",
    "            - ... \n",
    "        - test2: \n",
    "            - ... \n",
    "        - ... \n",
    "        \"\"\" \n",
    "        self.augmented = augmented\n",
    "        self.num_vids = num_vids \n",
    "        self.path_to_data = path_to_data \n",
    "        self.idx_map: List[Tuple[int, int]] = []\n",
    "        self.poses: Dict[int, np.ndarray] = {}\n",
    "        self.twists: Dict[int, np.ndarray] = {} \n",
    "        for i in tqdm(range(1, self.num_vids + 1)):\n",
    "            # Define path to pose \n",
    "            pose_path = os.path.join(path_to_data, f'test{i}/inputs/bd_poses.csv')\n",
    "            twist_path = os.path.join(path_to_data, f'test{i}/inputs/bd_twists.csv')\n",
    "\n",
    "            # Check that files were opened properly \n",
    "            if not os.path.isfile(pose_path):\n",
    "                raise FileNotFoundError(f\"Missing pose file: {pose_path}\")\n",
    "            if not os.path.isfile(twist_path):\n",
    "                raise FileNotFoundError(f\"Missing twist file: {twist_path}\")  \n",
    "\n",
    "            # Get poses \n",
    "            self.poses[i] = pd.read_csv(pose_path).to_numpy() \n",
    "            self.twists[i] = pd.read_csv(twist_path).to_numpy() \n",
    "\n",
    "            # Get pose data frame \n",
    "            num_frames = self.poses[i].shape[0] \n",
    "\n",
    "            # Update index map \n",
    "            video_num = [i] * num_frames \n",
    "            frame_idx = list(range(0, num_frames))\n",
    "            self.idx_map.extend(list(zip(video_num, frame_idx)))\n",
    "\n",
    "        self.total_num_frames = len(self.idx_map)\n",
    "\n",
    "    def __len__(self): \n",
    "        \"\"\"\n",
    "        Return length of dataset as computed in __init__() function. \n",
    "        \"\"\"\n",
    "        return self.total_num_frames \n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        \"\"\" \n",
    "        Use map built in __init__() to retrieve the image, \n",
    "        pose, and twist directly from the dataset. \n",
    "        This avoids loading the entire dataset which \n",
    "        overwhelms RAM. \n",
    "        \"\"\"\n",
    "        if torch.is_tensor(idx): \n",
    "            idx = idx.tolist() \n",
    "\n",
    "        # Define path to data \n",
    "        test_idx, frame_idx = self.idx_map[idx]\n",
    "        padded_frame_idx = self.to_zero_pad_idx(frame_idx) \n",
    "        input_img_path = os.path.join(self.path_to_data,\n",
    "                                f'test{test_idx}/inputs/frame{padded_frame_idx}.png')\n",
    "        output_img_path = os.path.join(self.path_to_data,\n",
    "                                f'test{test_idx}/targets/frame{padded_frame_idx}.png')\n",
    "        \n",
    "        # Load and process data \n",
    "        input_frame = io.imread(input_img_path)\n",
    "        output_frame = io.imread(output_img_path)\n",
    "        input_frame = self.to_grayscale(input_frame) \n",
    "        output_frame = self.to_grayscale(output_frame) \n",
    "        pose = self.poses[test_idx][frame_idx]\n",
    "        pose = self.pose_vector_from_matrix(pose)\n",
    "        twist = self.twists[test_idx][frame_idx]\n",
    "\n",
    "        if self.augmented: \n",
    "            h, w = input_frame.shape \n",
    "            expanded_frame = torch.from_numpy(input_frame).float().view(h, w, 1) \n",
    "            expanded_pose = torch.from_numpy(pose).float().view(1, 1, -1).repeat(h, w, 1)\n",
    "            expanded_twist = torch.from_numpy(twist).float().view(1, 1, -1).repeat(h, w, 1)  \n",
    "            augmented_frame = torch.cat((expanded_frame, expanded_pose, expanded_twist), dim=-1)\n",
    "            \n",
    "            return {'input': augmented_frame, 'target': torch.from_numpy(output_frame).float()}\n",
    "\n",
    "        return {'input': (torch.from_numpy(input_frame).float(), torch.from_numpy(pose).float(), torch.from_numpy(twist).float()), 'target': torch.from_numpy(output_frame).float()}\n",
    "\n",
    "    def to_zero_pad_idx(self, idx):\n",
    "        \"\"\" \n",
    "        Convert frame index from regular index to lexicographical index. \n",
    "        e.g. 1 -> 00001, 12 -> 00012 \n",
    "        \"\"\"\n",
    "        return f'{idx:05d}'\n",
    "\n",
    "    def pose_vector_from_matrix(self, pose): \n",
    "        \"\"\"\n",
    "        Convert 4x4 pose matrix (as a flattenned length 16 vector) into a position and quaternion length 7 vector. \n",
    "        \"\"\"\n",
    "        pose = pose.reshape(4, 4) \n",
    "        position = pose[:3, 3].reshape(3, 1) \n",
    "        orientation = pose[:3, :3]\n",
    "\n",
    "        quat = R.from_matrix(orientation).as_quat().reshape(-1, 1) \n",
    "        norm_quat = quat / np.linalg.norm(quat) \n",
    "\n",
    "        return np.vstack((position, norm_quat)).reshape(-1)\n",
    "\n",
    "    def to_grayscale(self, image):\n",
    "        \"\"\" \n",
    "        Convert PNG image to grayscale\n",
    "        \"\"\" \n",
    "        #TODO: Try float16 type \n",
    "        return (image[..., 0] > 127).astype(np.float32)\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 165.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# Make dataloader and load data \n",
    "path_to_data = '/home/jrached/cv_project_code/project/data/filter_net/processed_flow'\n",
    "dataset = VideoDataset(path_to_data, augmented=True)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=2) #NOTE: Don't remember what num_workers did nor why it matters \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoint = next(iter(loader))\n",
    "features = datapoint['input']\n",
    "labels = datapoint['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 480, 848, 14])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
