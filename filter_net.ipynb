{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FilterNet\n",
    "A neural network for filtering out gaussian noise from an image introduced by aggressive accelerations on the vehicle carrying the camera. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import torch \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from scipy.spatial.transform import Rotation as R \n",
    "from skimage import io, transform \n",
    "from PIL import Image   \n",
    "import matplotlib.pyplot as plt \n",
    "from torch.utils.data import Dataset, Dataloader \n",
    "from torchvision import transforms, utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloader \n",
    "\n",
    "#TODO: Load poses and twists once for each video in the __init__() function.\n",
    "# This takes up more RAM but significantly reduces input and output overhead. \n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, path_to_data, num_vids=7):\n",
    "        \"\"\"\n",
    "        Go through each video folder and build a map from \n",
    "        index i in range [0, N], where N is the total number\n",
    "        of frames in all the videos, to a tuple (j, k), where \n",
    "        j is the video number and k the frame index in that \n",
    "        video. For reference, the videos are stored in the \n",
    "        dataset as:  \n",
    "\n",
    "        data: \n",
    "        - test1: \n",
    "          - video:\n",
    "            - frame0001.png\n",
    "            - ... \n",
    "          - poses: \n",
    "            - poses.csv\n",
    "            - twists.csv\n",
    "        - test2: \n",
    "            - ... \n",
    "        - ... \n",
    "        \"\"\" \n",
    "        self.num_vids = num_vids \n",
    "        self.path_to_data = path_to_data \n",
    "        self.idx_map = []\n",
    "        for i in range(1, self.num_vids + 1):\n",
    "            # Get pose data frame \n",
    "            num_frames = pd.read_csv(path_to_data + f'/test{i}/poses/poses.csv').to_numpy().shape[0] \n",
    "\n",
    "            # Update index map \n",
    "            video_num = [i] * num_frames \n",
    "            frame_idx = list(range(0, num_frames))\n",
    "            self.idx_map += list(zip(video_num, frame_idx))\n",
    "\n",
    "        self.total_num_frames = len(self.idx_map)\n",
    "\n",
    "    def __len__(self): \n",
    "        \"\"\"\n",
    "        Return length of dataset as computed in __init__() function. \n",
    "        \"\"\"\n",
    "        return self.total_num_frames \n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        \"\"\" \n",
    "        Use map built in __init__() to retrieve the image, \n",
    "        pose, and twist directly from the dataset. \n",
    "        This avoids loading the entire dataset which \n",
    "        overwhelms the RAM. \n",
    "        \"\"\"\n",
    "        if torch.is_tensor(idx): \n",
    "            idx = idx.tolist() \n",
    "\n",
    "        test_idx, frame_idx = self.idx_map[idx]\n",
    "        lexi_frame_idx = self.to_lexi_idx(frame_idx) \n",
    "        img_path = os.path.join(self.path_to_data,\n",
    "                                f'/test{test_idx}/video/frame{lexi_frame_idx}.png')\n",
    "        pose_path = os.path.join(self.path_to_data, \n",
    "                                 f'/test{test_idx}/poses/pose.csv')\n",
    "        twist_path = os.path.join(self.path_to_data, \n",
    "                                 f'/test{test_idx}/poses/twist.csv')\n",
    "        \n",
    "        frame = io.imread(img_path)\n",
    "        frame = self.to_grayscale_bitmask(frame) \n",
    "        pose = pd.read_csv(pose_path).to_numpy()[frame_idx]\n",
    "        pose = self.pose_matrix_to_vector(pose)\n",
    "        twist = pd.read_csv(twist_path).to_numpy()[frame_idx]\n",
    "\n",
    "        return frame, torch.from_numpy(pose), torch.from_numpy(twist) \n",
    "\n",
    "    def to_lexi_idx(self, idx):\n",
    "        \"\"\" \n",
    "        Convert frame index from regular index to lexicographical index. \n",
    "        e.g. 1 -> 00001, 12 -> 00012 \n",
    "        \"\"\"\n",
    "        #TODO: Implement.\n",
    "        pass \n",
    "\n",
    "    def pose_matrix_to_vector(self, pose): \n",
    "        \"\"\"\n",
    "        Convert 4x4 pose matrix into a position and quaternion length 7 vector. \n",
    "        \"\"\"\n",
    "        position = pose[:3, 3].reshape(3, 1) \n",
    "        orientation = pose[:3, :3]\n",
    "\n",
    "        quat = R.from_matrix(orientation).as_quat().reshape(-1, 1) \n",
    "        norm_quat = quat / np.linalg.norm(quat) \n",
    "\n",
    "        return np.hstack((position, norm_quat))\n",
    "\n",
    "    def to_grayscale_bitmask(self, image):\n",
    "        \"\"\" \n",
    "        Convert PNG image to grayscale bitmask \n",
    "        \"\"\" \n",
    "        #TODO: Implement. \n",
    "        pass \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = ''\n",
    "dataset = VideoDataset(path_to_data)\n",
    "loader = Dataloader(dataset, batch_size=64, shuffle=False, num_workers=4) #NOTE: Don't remember what num_workers did nor why it matters \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kalman_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
